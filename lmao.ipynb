{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "got_ver is None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m functional \u001b[39mas\u001b[39;00m F\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionPipeline, AutoencoderKL\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschedulers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscheduling_ddim\u001b[39;00m \u001b[39mimport\u001b[39;00m DDIMScheduler\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/diffusers/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.14.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfiguration_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigMixin\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m      6\u001b[0m     is_flax_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     logging,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/diffusers/configuration_utils.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrequests\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPError\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m DIFFUSERS_CACHE, HUGGINGFACE_CO_RESOLVE_ENDPOINT, DummyObject, deprecate, logging\n\u001b[1;32m     37\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     39\u001b[0m _re_configuration_file \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.(.*)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/diffusers/utils/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerate_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_forward_hook\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     24\u001b[0m     DEPRECATED_REVISION_ARGS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecate\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_accelerate_available\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_forward_hook\u001b[39m(method):\n\u001b[1;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m    Decorator that applies a registered CpuOffload hook to an arbitrary function rather than `forward`. This is useful\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    for cases where a PyTorch module provides functions other than `forward` that should trigger a move to the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m    :param method: The method to decorate. This method should be a method of a PyTorch module.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.15.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbig_modeling\u001b[39;00m \u001b[39mimport\u001b[39;00m cpu_offload, disk_offload, dispatch_model, init_empty_weights, load_checkpoint_and_dispatch\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunchers\u001b[39;00m \u001b[39mimport\u001b[39;00m debug_launcher, notebook_launcher\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/accelerator.py:27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List, Optional, Union\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcheckpointing\u001b[39;00m \u001b[39mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m get_logger\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     save,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m is_tpu_available(check_device\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch_xla\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla_model\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxm\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/utils/__init__.py:103\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m     95\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunch\u001b[39;00m \u001b[39mimport\u001b[39;00m PrepareForLaunch, _filter_args, get_launch_prefix\n\u001b[0;32m--> 103\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    104\u001b[0m     AbstractTrainStep,\n\u001b[1;32m    105\u001b[0m     BertTrainStep,\n\u001b[1;32m    106\u001b[0m     GPTTrainStep,\n\u001b[1;32m    107\u001b[0m     MegatronEngine,\n\u001b[1;32m    108\u001b[0m     MegatronLMDummyDataLoader,\n\u001b[1;32m    109\u001b[0m     MegatronLMDummyScheduler,\n\u001b[1;32m    110\u001b[0m     MegatronLMOptimizerWrapper,\n\u001b[1;32m    111\u001b[0m     MegatronLMSchedulerWrapper,\n\u001b[1;32m    112\u001b[0m     T5TrainStep,\n\u001b[1;32m    113\u001b[0m     avg_losses_across_data_parallel_group,\n\u001b[1;32m    114\u001b[0m     gather_across_data_parallel_groups,\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize \u001b[39mas\u001b[39;00m megatron_lm_initialize\n\u001b[1;32m    117\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_data_loader \u001b[39mas\u001b[39;00m megatron_lm_prepare_data_loader\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/utils/megatron_lm.py:32\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39moperations\u001b[39;00m \u001b[39mimport\u001b[39;00m recursively_apply, send_to_device\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m is_transformers_available():\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m         CausalLMOutputWithCrossAttentions,\n\u001b[1;32m     34\u001b[0m         Seq2SeqLMOutput,\n\u001b[1;32m     35\u001b[0m         SequenceClassifierOutput,\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m is_megatron_lm_available():\n\u001b[1;32m     40\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmegatron\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m         get_args,\n\u001b[1;32m     42\u001b[0m         get_num_microbatches,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m         print_rank_last,\n\u001b[1;32m     49\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     logging,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     47\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/dependency_versions_check.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m     39\u001b[0m             \u001b[39mcontinue\u001b[39;00m  \u001b[39m# not required, check version only if installed\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     require_version_core(deps[pkg])\n\u001b[1;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m{\u001b[39;00mpkg\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mdeps\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m, check dependency_versions_table.py\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/versions.py:120\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m hint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTry: pip install transformers -U or pip install -e \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.[dev]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m if you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre working with git main\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m require_version(requirement, hint)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/versions.py:114\u001b[0m, in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m want_ver \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[39mfor\u001b[39;00m op, want_ver \u001b[39min\u001b[39;00m wanted\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 114\u001b[0m         _compare_versions(op, got_ver, want_ver, requirement, pkg, hint)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/versions.py:45\u001b[0m, in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compare_versions\u001b[39m(op, got_ver, want_ver, requirement, pkg, hint):\n\u001b[1;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m got_ver \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgot_ver is None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m want_ver \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mwant_ver is None\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: got_ver is None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "import torch\n",
    "from torch import autocast\n",
    "from torch.nn import functional as F\n",
    "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
    "from diffusers import UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler\n",
    "from diffusers.schedulers.scheduling_ddim import DDIMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import notebook_login\n",
    "from google.colab import output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
